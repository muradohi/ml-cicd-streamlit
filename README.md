# ML CI/CD (Streamlit, GridSearchCV, GitHub Actions, Docker)
## ðŸ“‹ Details of the Work

This project is a **production-style template** for predicting **Employee Churn** with a complete, reproducible **ML + MLOps** workflow. It demonstrates how to go from a CSV dataset to a trained, tuned model and a deployable **Streamlit** app using **CI/CD with GitHub Actions** and **Docker** (pushed to **GitHub Container Registry**).

### ðŸŽ¯ Objectives
- Build a **config-driven** ML pipeline for churn prediction
- Handle **mixed data** (numeric + categorical) with a robust preprocessing pipeline
- Perform **hyperparameter tuning** using **GridSearchCV** with **K-fold cross-validation**
- Save and serve the **best estimator** via a Streamlit app
- Automate **testing (CI)** and **train â†’ build â†’ publish (CD)** using GitHub Actions
- Containerize the app and publish to **GHCR** for easy, portable deployment
- Use a **branching strategy** (`murad` â†’ PR â†’ `main`) to reflect real-world workflows

### ðŸ§  Dataset
The target is **`Churn`** (0 = stay, 1 = leave).  
Example features (editable in `configs/config.yaml`):
- **Numeric:** `Age`, `Tenure`, `Salary`, `Performance Rating`, `Projects Completed`, `Training Hours`, `Promotions`, `Overtime Hours`, `Satisfaction Level`, `Average Monthly Hours Worked`, `Absenteeism`, `Distance from Home`, `Manager Feedback Score`
- **Categorical:** `Gender`, `Education Level`, `Marital Status`, `Job Role`, `Department`, `Work Location`, `Work-Life Balance`

### ðŸ§© Methodology
- **Preprocessing:** `ColumnTransformer` â†’ `StandardScaler` (numeric) + `OneHotEncoder` (categorical)
- **Model:** `LogisticRegression`
- **Tuning:** `GridSearchCV` over hyperparameters (e.g., `C`, `solver`)
- **Validation:** `K-fold` cross-validation (configurable via `cv_folds`)
- **Selection:** Persist **best model** to `artifacts/best_model.pkl`

### ðŸ—ï¸ System Pipeline
1. **Config** (`configs/config.yaml`) defines features, CV, scoring, and grid.
2. **Training** (`src/train.py`) loads data, builds pipeline, runs GridSearchCV, evaluates, saves best model.
3. **App** (`app/app.py`) loads the saved model and serves predictions via Streamlit.
4. **CI** (`.github/workflows/ci.yml`) runs tests on every push/PR.
5. **CD** (`.github/workflows/cd.yml`) trains on push to branches (e.g., `murad`, `main`), builds Docker, pushes to **GHCR**.

```text
CSV â†’ config.yaml â†’ (preprocess + GridSearchCV + CV) â†’ best_model.pkl
                                      â”‚
                                      â””â”€> Streamlit UI (interactive inference)
CI: pytest on push/PR  |  CD: train â†’ docker build â†’ push :latest to GHCR

